{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# list of stopwords like articles, preposition\n",
    "stop = set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "from collections import Counter\n",
    "import re\n",
    "import lda\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422937, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CATEGORY: News category (b = business, t = science and technology, e = entertainment, m = health) \n",
    "column_names = ['id','title','url','publisher','category','story','hostname','timestamp']\n",
    "data = pd.read_csv('./newsCorpora.csv', header = None, names = column_names)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news=data.groupby('category', group_keys=False).apply(lambda x: x.sample(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD7CAYAAACMlyg3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ed02e4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news.category.value_counts().plot(kind='bar',grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>category</th>\n",
       "      <th>story</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364598</th>\n",
       "      <td>364599</td>\n",
       "      <td>VIDEO: Two planes have serious near-miss at Ba...</td>\n",
       "      <td>http://www.breakingnews.ie/discover/video-two-...</td>\n",
       "      <td>BreakingNews.ie</td>\n",
       "      <td>b</td>\n",
       "      <td>dUAXUDNU8EuVDUMCq0qglFi336usM</td>\n",
       "      <td>www.breakingnews.ie</td>\n",
       "      <td>1.404760e+12</td>\n",
       "      <td>video two planes have serious near miss at bar...</td>\n",
       "      <td>[video, two, plane, seriou, near, miss, barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90891</th>\n",
       "      <td>90892</td>\n",
       "      <td>IMF Says US Growth Leads as Russia, Brazil Sof...</td>\n",
       "      <td>http://www.businessweek.com/news/2014-04-08/im...</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>b</td>\n",
       "      <td>dxB9Hik1YGyfVaMk796CJSnAf58bM</td>\n",
       "      <td>www.businessweek.com</td>\n",
       "      <td>1.396990e+12</td>\n",
       "      <td>imf says us growth leads as russia brazil soft...</td>\n",
       "      <td>[imf, say, us, growth, lead, russia, brazil, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173354</th>\n",
       "      <td>173355</td>\n",
       "      <td>ECB Squeezed And EBA Posts Stress Test Scenarios</td>\n",
       "      <td>http://seekingalpha.com/article/2172223-ecb-sq...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>b</td>\n",
       "      <td>d6oH4km9IXNQhDMMjOqbrYbTbVjcM</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "      <td>1.398860e+12</td>\n",
       "      <td>ecb squeezed and eba posts stress test scenarios</td>\n",
       "      <td>[ecb, squeez, eba, post, stress, test, scenario]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196094</th>\n",
       "      <td>196095</td>\n",
       "      <td>Yellen: Raising Minimum Wage Would Have Positi...</td>\n",
       "      <td>http://www.nasdaq.com/article/yellen-raising-m...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>b</td>\n",
       "      <td>d06p_B068Tz-trM0VOb3T9IS-s-rM</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.399620e+12</td>\n",
       "      <td>yellen raising minimum wage would have positiv...</td>\n",
       "      <td>[yellen, rais, minimum, wage, would, posit, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44394</th>\n",
       "      <td>44395</td>\n",
       "      <td>Top JPMorgan Exec Cavanagh Jumps to Carlyle Group</td>\n",
       "      <td>http://www.foxbusiness.com/industries/2014/03/...</td>\n",
       "      <td>Fox Business</td>\n",
       "      <td>b</td>\n",
       "      <td>dTHeoUzEPQp6XNMPBKBlQ9ys5UB4M</td>\n",
       "      <td>www.foxbusiness.com</td>\n",
       "      <td>1.395830e+12</td>\n",
       "      <td>top jpmorgan exec cavanagh jumps to carlyle group</td>\n",
       "      <td>[top, jpmorgan, exec, cavanagh, jump, carlyl, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "364598  364599  VIDEO: Two planes have serious near-miss at Ba...   \n",
       "90891    90892  IMF Says US Growth Leads as Russia, Brazil Sof...   \n",
       "173354  173355   ECB Squeezed And EBA Posts Stress Test Scenarios   \n",
       "196094  196095  Yellen: Raising Minimum Wage Would Have Positi...   \n",
       "44394    44395  Top JPMorgan Exec Cavanagh Jumps to Carlyle Group   \n",
       "\n",
       "                                                      url        publisher  \\\n",
       "364598  http://www.breakingnews.ie/discover/video-two-...  BreakingNews.ie   \n",
       "90891   http://www.businessweek.com/news/2014-04-08/im...     Businessweek   \n",
       "173354  http://seekingalpha.com/article/2172223-ecb-sq...    Seeking Alpha   \n",
       "196094  http://www.nasdaq.com/article/yellen-raising-m...           NASDAQ   \n",
       "44394   http://www.foxbusiness.com/industries/2014/03/...     Fox Business   \n",
       "\n",
       "       category                          story              hostname  \\\n",
       "364598        b  dUAXUDNU8EuVDUMCq0qglFi336usM   www.breakingnews.ie   \n",
       "90891         b  dxB9Hik1YGyfVaMk796CJSnAf58bM  www.businessweek.com   \n",
       "173354        b  d6oH4km9IXNQhDMMjOqbrYbTbVjcM      seekingalpha.com   \n",
       "196094        b  d06p_B068Tz-trM0VOb3T9IS-s-rM        www.nasdaq.com   \n",
       "44394         b  dTHeoUzEPQp6XNMPBKBlQ9ys5UB4M   www.foxbusiness.com   \n",
       "\n",
       "           timestamp                                               text  \\\n",
       "364598  1.404760e+12  video two planes have serious near miss at bar...   \n",
       "90891   1.396990e+12  imf says us growth leads as russia brazil soft...   \n",
       "173354  1.398860e+12   ecb squeezed and eba posts stress test scenarios   \n",
       "196094  1.399620e+12  yellen raising minimum wage would have positiv...   \n",
       "44394   1.395830e+12  top jpmorgan exec cavanagh jumps to carlyle group   \n",
       "\n",
       "                                                   tokens  \n",
       "364598  [video, two, plane, seriou, near, miss, barcel...  \n",
       "90891   [imf, say, us, growth, lead, russia, brazil, s...  \n",
       "173354   [ecb, squeez, eba, post, stress, test, scenario]  \n",
       "196094  [yellen, rais, minimum, wage, would, posit, ne...  \n",
       "44394   [top, jpmorgan, exec, cavanagh, jump, carlyl, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data: remove punctuations, user mentions, hashtages and urls\n",
    "def clean_text(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Utility function to clean tweet text by removing links, special characters using simple regex statements.\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(\\d+)\", \" \", tweet).split())\n",
    "\n",
    "news['text'] = [clean_text(s) for s in news['title']]\n",
    "\n",
    "#Tokenization  \n",
    "def tokenizer(text):\n",
    "    try:\n",
    "        tokens_ = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "        \n",
    "        tokens = []\n",
    "        for token_by_sent in tokens_:\n",
    "            tokens += token_by_sent\n",
    "\n",
    "        tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "        tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "        tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\", u\"...\", u\"''\", u'``', \n",
    "                                            u'\\u2014', u'\\u2026', u'\\u2013'], tokens))\n",
    "        #Stemming, reduce topically similar words to their root\n",
    "        tokens = [p_stemmer.stem(t) for t in tokens]\n",
    "        \n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            if re.search('[a-zA-Z]', token):\n",
    "                filtered_tokens.append(token)\n",
    "\n",
    "        filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "\n",
    "        return filtered_tokens\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "news['tokens'] = news['text'].map(tokenizer)\n",
    "\n",
    "news.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category : e\n",
      "top 10 keywords: [('new', 116), ('video', 78), ('season', 76), ('kim', 72), ('kardashian', 72), ('game', 66), ('star', 65), ('review', 63), ('movie', 63), ('first', 56)]\n",
      "---\n",
      "category : m\n",
      "top 10 keywords: [('ebola', 192), ('study', 145), ('cancer', 131), ('new', 120), ('health', 119), ('may', 95), ('virus', 94), ('us', 91), ('mers', 86), ('outbreak', 80)]\n",
      "---\n",
      "category : t\n",
      "top 10 keywords: [('google', 224), ('apple', 172), ('new', 156), ('samsung', 132), ('microsoft', 106), ('facebook', 104), ('galaxy', 97), ('android', 81), ('one', 76), ('us', 64)]\n",
      "---\n",
      "category : b\n",
      "top 10 keywords: [('us', 195), ('china', 100), ('stocks', 90), ('new', 78), ('says', 61), ('bank', 60), ('market', 57), ('billion', 56), ('sales', 56), ('data', 50)]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#group the tokens by category, apply a word count and display the top 10 most frequent tokens\n",
    "def keywords(category):\n",
    "    tokens = news[news['category'] == category]['tokens']\n",
    "    alltokens = []\n",
    "    for token_list in tokens:\n",
    "        alltokens += token_list\n",
    "    counter = Counter(alltokens)\n",
    "    return counter.most_common(10)\n",
    "\n",
    "for category in set(news['category']):\n",
    "    print('category :', category)\n",
    "    print('top 10 keywords:', keywords(category))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422937, 20000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df is minimum number of documents that contain a term t\n",
    "# max_features is maximum number of unique tokens (across documents) that we'd consider\n",
    "# TfidfVectorizer preprocesses the descriptions using the tokenizer we defined above\n",
    "vectorizer = TfidfVectorizer(min_df=10, max_features=None, tokenizer=tokenizer, ngram_range=(1, 2))\n",
    "\n",
    "# vz is a tfidf matrix\n",
    "#its number of rows is the total number of news\n",
    "#its number of columns is the total number of unique terms (tokens) across the news\n",
    "vz = vectorizer.fit_transform(list(news['text']))\n",
    "vz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a dictionary mapping the tokens to their tfidf values\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "tfidf = pd.DataFrame(columns=['tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "tfidf.columns = ['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>3.866509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>4.197676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>4.555757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>4.715082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>4.783485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>4.845456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>4.918875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>4.962175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>4.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft</th>\n",
       "      <td>5.098605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>5.126926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>5.155168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>5.203665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>5.222193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>5.234684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>5.242385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>5.272104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kardashian</th>\n",
       "      <td>5.290575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>5.295074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>china</th>\n",
       "      <td>5.306759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>5.320360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>5.329472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>5.353630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>5.381975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon</th>\n",
       "      <td>5.433397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>5.442197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>5.449051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stocks</th>\n",
       "      <td>5.453104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deal</th>\n",
       "      <td>5.454120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>5.469278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "new         3.866509\n",
       "us          4.197676\n",
       "google      4.555757\n",
       "apple       4.715082\n",
       "video       4.783485\n",
       "says        4.845456\n",
       "first       4.918875\n",
       "samsung     4.962175\n",
       "may         4.999920\n",
       "microsoft   5.098605\n",
       "one         5.126926\n",
       "facebook    5.155168\n",
       "report      5.203665\n",
       "galaxy      5.222193\n",
       "watch       5.234684\n",
       "day         5.242385\n",
       "star        5.272104\n",
       "kardashian  5.290575\n",
       "kim         5.295074\n",
       "china       5.306759\n",
       "season      5.320360\n",
       "game        5.329472\n",
       "review      5.353630\n",
       "million     5.381975\n",
       "amazon      5.433397\n",
       "sales       5.442197\n",
       "could       5.449051\n",
       "stocks      5.453104\n",
       "deal        5.454120\n",
       "year        5.469278"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the 30 tokens that have the lowest tfidf scores\n",
    "tfidf.sort_values(by=['tfidf'], ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blah</th>\n",
       "      <td>11.557086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cha cha</th>\n",
       "      <td>10.910458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quot</th>\n",
       "      <td>10.819487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctos</th>\n",
       "      <td>10.776927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little bit</th>\n",
       "      <td>10.776927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>10.776927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peer</th>\n",
       "      <td>10.776927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hummus dips</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un agency</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boj kuroda</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ice ages</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infectious</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaw</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social data</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wop</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>believers</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triggered</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update amazon</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tif</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ian ziering</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infects</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilot error</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intended</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean water</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pump prices</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrested public</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caesars</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wilmore replace</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leo</th>\n",
       "      <td>10.736105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tfidf\n",
       "blah             11.557086\n",
       "cha cha          10.910458\n",
       "quot             10.819487\n",
       "ctos             10.776927\n",
       "little bit       10.776927\n",
       "yeah             10.776927\n",
       "peer             10.776927\n",
       "hummus dips      10.736105\n",
       "un agency        10.736105\n",
       "boj kuroda       10.736105\n",
       "insured          10.736105\n",
       "ice ages         10.736105\n",
       "infectious       10.736105\n",
       "jaw              10.736105\n",
       "social data      10.736105\n",
       "wop              10.736105\n",
       "believers        10.736105\n",
       "triggered        10.736105\n",
       "update amazon    10.736105\n",
       "tif              10.736105\n",
       "ian ziering      10.736105\n",
       "infects          10.736105\n",
       "pilot error      10.736105\n",
       "intended         10.736105\n",
       "clean water      10.736105\n",
       "pump prices      10.736105\n",
       "arrested public  10.736105\n",
       "caesars          10.736105\n",
       "wilmore replace  10.736105\n",
       "leo              10.736105"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out the 30 words with the highest tfidf scores\n",
    "tfidf.sort_values(by=['tfidf'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = news[~news['category'].isnull()& ~news['text'].isnull()]\n",
    "\n",
    "# pull the data into vectors\n",
    "vectorizer = CountVectorizer(min_df=10, max_features=None, tokenizer=tokenizer)\n",
    "x_vec = vectorizer.fit_transform(news['text'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "ncategory = encoder.fit_transform(news['category'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(news['text']),ncategory, test_size=0.2, stratify=ncategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_p=[[y_train[i]] for i in range(len(y_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_SVC.fit(x_train[:100000], y_train[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n          t       0.97      0.02      0.05     23209\\n          e       0.99      0.28      0.44     30694\\n          b       0.93      0.29      0.45      9178\\n          m       0.30      1.00      0.46     21505\\n\\navg / total       0.80      0.39      0.34     84586\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model_SVC.predict(x_test)\n",
    "labels = list(set(news['category']))\n",
    "metrics.classification_report(y_test, y_pred, target_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the Naive Bayes model\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          t       0.91      0.90      0.90     23194\n",
      "          e       0.96      0.96      0.96     30564\n",
      "          b       0.92      0.92      0.92      9128\n",
      "          m       0.89      0.91      0.90     21700\n",
      "\n",
      "avg / total       0.92      0.92      0.92     84586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=nb.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "text_clf.fit(x_train, y_train_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          e       0.87      0.77      0.82       400\n",
      "          m       0.91      0.91      0.91       400\n",
      "          t       0.90      0.91      0.90       400\n",
      "          b       0.80      0.87      0.83       400\n",
      "\n",
      "avg / total       0.87      0.86      0.86      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=text_clf.predict(x_test)\n",
    "labels = list(set(news['category']))\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 8000\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 1.256771\n",
      "[t-SNE] Error after 350 iterations: 1.256771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\bokeh\\util\\deprecation.py:34: BokehDeprecationWarning: \n",
      "Supplying a user-defined data source AND iterable values to glyph methods is deprecated.\n",
      "\n",
      "See https://github.com/bokeh/bokeh/issues/2056 for more information.\n",
      "\n",
      "  warn(message)\n",
      "C:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\bokeh\\util\\deprecation.py:34: BokehDeprecationWarning: \n",
      "Supplying a user-defined data source AND iterable values to glyph methods is deprecated.\n",
      "\n",
      "See https://github.com/bokeh/bokeh/issues/2056 for more information.\n",
      "\n",
      "  warn(message)\n"
     ]
    }
   ],
   "source": [
    "#visulize the topic categories\n",
    "#reducing the dimension of each vector to 50 by SVD.\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=50, random_state=0)\n",
    "svd_tfidf = svd.fit_transform(x_vec)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0)\n",
    "tsne_vec = tsne_model.fit_transform(svd_tfidf)\n",
    "\n",
    "tsne_df = pd.DataFrame(tsne_vec, columns=['x', 'y'])\n",
    "tsne_df['text'] = news['text']\n",
    "tsne_df['category'] = ncategory\n",
    "\n",
    "plot_news = bp.figure(plot_width=700, plot_height=600, title=\"A map of news\",\n",
    "    tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "    x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "colormap = np.array([\"#6d8dca\", \"#69de53\",\"#723bca\", \"#c3e14c\"])\n",
    "plot_news.scatter(x='x', y='y', \n",
    "                    color=colormap[tsne_df['category']], \n",
    "                    source=tsne_df)\n",
    "hover = plot_news.select(dict(type=HoverTool))\n",
    "hover.tooltips={\"text\": \"@text\", \"category\": \"@category\"}\n",
    "show(plot_news) \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 8000\n",
      "INFO:lda:vocab_size: 1262\n",
      "INFO:lda:n_words: 32138\n",
      "INFO:lda:n_topics: 4\n",
      "INFO:lda:n_iter: 2000\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -315369\n",
      "INFO:lda:<10> log likelihood: -243829\n",
      "INFO:lda:<20> log likelihood: -237826\n",
      "INFO:lda:<30> log likelihood: -235590\n",
      "INFO:lda:<40> log likelihood: -234344\n",
      "INFO:lda:<50> log likelihood: -233256\n",
      "INFO:lda:<60> log likelihood: -232531\n",
      "INFO:lda:<70> log likelihood: -231720\n",
      "INFO:lda:<80> log likelihood: -231218\n",
      "INFO:lda:<90> log likelihood: -230867\n",
      "INFO:lda:<100> log likelihood: -230534\n",
      "INFO:lda:<110> log likelihood: -230161\n",
      "INFO:lda:<120> log likelihood: -229645\n",
      "INFO:lda:<130> log likelihood: -229366\n",
      "INFO:lda:<140> log likelihood: -229204\n",
      "INFO:lda:<150> log likelihood: -228933\n",
      "INFO:lda:<160> log likelihood: -228619\n",
      "INFO:lda:<170> log likelihood: -228461\n",
      "INFO:lda:<180> log likelihood: -228263\n",
      "INFO:lda:<190> log likelihood: -228130\n",
      "INFO:lda:<200> log likelihood: -227941\n",
      "INFO:lda:<210> log likelihood: -227943\n",
      "INFO:lda:<220> log likelihood: -227835\n",
      "INFO:lda:<230> log likelihood: -227916\n",
      "INFO:lda:<240> log likelihood: -227857\n",
      "INFO:lda:<250> log likelihood: -227537\n",
      "INFO:lda:<260> log likelihood: -227930\n",
      "INFO:lda:<270> log likelihood: -227785\n",
      "INFO:lda:<280> log likelihood: -227472\n",
      "INFO:lda:<290> log likelihood: -227574\n",
      "INFO:lda:<300> log likelihood: -227457\n",
      "INFO:lda:<310> log likelihood: -227362\n",
      "INFO:lda:<320> log likelihood: -227372\n",
      "INFO:lda:<330> log likelihood: -227347\n",
      "INFO:lda:<340> log likelihood: -227203\n",
      "INFO:lda:<350> log likelihood: -227166\n",
      "INFO:lda:<360> log likelihood: -227156\n",
      "INFO:lda:<370> log likelihood: -227109\n",
      "INFO:lda:<380> log likelihood: -227056\n",
      "INFO:lda:<390> log likelihood: -227306\n",
      "INFO:lda:<400> log likelihood: -227292\n",
      "INFO:lda:<410> log likelihood: -227104\n",
      "INFO:lda:<420> log likelihood: -227181\n",
      "INFO:lda:<430> log likelihood: -227385\n",
      "INFO:lda:<440> log likelihood: -227019\n",
      "INFO:lda:<450> log likelihood: -227136\n",
      "INFO:lda:<460> log likelihood: -227203\n",
      "INFO:lda:<470> log likelihood: -227208\n",
      "INFO:lda:<480> log likelihood: -227135\n",
      "INFO:lda:<490> log likelihood: -227171\n",
      "INFO:lda:<500> log likelihood: -226846\n",
      "INFO:lda:<510> log likelihood: -227169\n",
      "INFO:lda:<520> log likelihood: -227048\n",
      "INFO:lda:<530> log likelihood: -226992\n",
      "INFO:lda:<540> log likelihood: -226911\n",
      "INFO:lda:<550> log likelihood: -226995\n",
      "INFO:lda:<560> log likelihood: -227029\n",
      "INFO:lda:<570> log likelihood: -227024\n",
      "INFO:lda:<580> log likelihood: -226920\n",
      "INFO:lda:<590> log likelihood: -226963\n",
      "INFO:lda:<600> log likelihood: -226965\n",
      "INFO:lda:<610> log likelihood: -226934\n",
      "INFO:lda:<620> log likelihood: -227106\n",
      "INFO:lda:<630> log likelihood: -227140\n",
      "INFO:lda:<640> log likelihood: -227106\n",
      "INFO:lda:<650> log likelihood: -227084\n",
      "INFO:lda:<660> log likelihood: -226942\n",
      "INFO:lda:<670> log likelihood: -226993\n",
      "INFO:lda:<680> log likelihood: -226808\n",
      "INFO:lda:<690> log likelihood: -226792\n",
      "INFO:lda:<700> log likelihood: -227066\n",
      "INFO:lda:<710> log likelihood: -227077\n",
      "INFO:lda:<720> log likelihood: -227165\n",
      "INFO:lda:<730> log likelihood: -227031\n",
      "INFO:lda:<740> log likelihood: -226930\n",
      "INFO:lda:<750> log likelihood: -227057\n",
      "INFO:lda:<760> log likelihood: -226900\n",
      "INFO:lda:<770> log likelihood: -227033\n",
      "INFO:lda:<780> log likelihood: -227027\n",
      "INFO:lda:<790> log likelihood: -226897\n",
      "INFO:lda:<800> log likelihood: -226894\n",
      "INFO:lda:<810> log likelihood: -226946\n",
      "INFO:lda:<820> log likelihood: -226830\n",
      "INFO:lda:<830> log likelihood: -226816\n",
      "INFO:lda:<840> log likelihood: -227056\n",
      "INFO:lda:<850> log likelihood: -226954\n",
      "INFO:lda:<860> log likelihood: -226794\n",
      "INFO:lda:<870> log likelihood: -226765\n",
      "INFO:lda:<880> log likelihood: -226696\n",
      "INFO:lda:<890> log likelihood: -226724\n",
      "INFO:lda:<900> log likelihood: -226732\n",
      "INFO:lda:<910> log likelihood: -226520\n",
      "INFO:lda:<920> log likelihood: -226396\n",
      "INFO:lda:<930> log likelihood: -226213\n",
      "INFO:lda:<940> log likelihood: -226399\n",
      "INFO:lda:<950> log likelihood: -226130\n",
      "INFO:lda:<960> log likelihood: -226201\n",
      "INFO:lda:<970> log likelihood: -226278\n",
      "INFO:lda:<980> log likelihood: -225935\n",
      "INFO:lda:<990> log likelihood: -225903\n",
      "INFO:lda:<1000> log likelihood: -225758\n",
      "INFO:lda:<1010> log likelihood: -225893\n",
      "INFO:lda:<1020> log likelihood: -225856\n",
      "INFO:lda:<1030> log likelihood: -225886\n",
      "INFO:lda:<1040> log likelihood: -226002\n",
      "INFO:lda:<1050> log likelihood: -225979\n",
      "INFO:lda:<1060> log likelihood: -225645\n",
      "INFO:lda:<1070> log likelihood: -225878\n",
      "INFO:lda:<1080> log likelihood: -225955\n",
      "INFO:lda:<1090> log likelihood: -225807\n",
      "INFO:lda:<1100> log likelihood: -226132\n",
      "INFO:lda:<1110> log likelihood: -226045\n",
      "INFO:lda:<1120> log likelihood: -225933\n",
      "INFO:lda:<1130> log likelihood: -225812\n",
      "INFO:lda:<1140> log likelihood: -225822\n",
      "INFO:lda:<1150> log likelihood: -225777\n",
      "INFO:lda:<1160> log likelihood: -225692\n",
      "INFO:lda:<1170> log likelihood: -225785\n",
      "INFO:lda:<1180> log likelihood: -225676\n",
      "INFO:lda:<1190> log likelihood: -225612\n",
      "INFO:lda:<1200> log likelihood: -225795\n",
      "INFO:lda:<1210> log likelihood: -225736\n",
      "INFO:lda:<1220> log likelihood: -225833\n",
      "INFO:lda:<1230> log likelihood: -225717\n",
      "INFO:lda:<1240> log likelihood: -225752\n",
      "INFO:lda:<1250> log likelihood: -225741\n",
      "INFO:lda:<1260> log likelihood: -225784\n",
      "INFO:lda:<1270> log likelihood: -225730\n",
      "INFO:lda:<1280> log likelihood: -225810\n",
      "INFO:lda:<1290> log likelihood: -225804\n",
      "INFO:lda:<1300> log likelihood: -225709\n",
      "INFO:lda:<1310> log likelihood: -225750\n",
      "INFO:lda:<1320> log likelihood: -225723\n",
      "INFO:lda:<1330> log likelihood: -225754\n",
      "INFO:lda:<1340> log likelihood: -225991\n",
      "INFO:lda:<1350> log likelihood: -225707\n",
      "INFO:lda:<1360> log likelihood: -225822\n",
      "INFO:lda:<1370> log likelihood: -226075\n",
      "INFO:lda:<1380> log likelihood: -225877\n",
      "INFO:lda:<1390> log likelihood: -225672\n",
      "INFO:lda:<1400> log likelihood: -225812\n",
      "INFO:lda:<1410> log likelihood: -225830\n",
      "INFO:lda:<1420> log likelihood: -226058\n",
      "INFO:lda:<1430> log likelihood: -225630\n",
      "INFO:lda:<1440> log likelihood: -225846\n",
      "INFO:lda:<1450> log likelihood: -225782\n",
      "INFO:lda:<1460> log likelihood: -225793\n",
      "INFO:lda:<1470> log likelihood: -225780\n",
      "INFO:lda:<1480> log likelihood: -225806\n",
      "INFO:lda:<1490> log likelihood: -225991\n",
      "INFO:lda:<1500> log likelihood: -225739\n",
      "INFO:lda:<1510> log likelihood: -225505\n",
      "INFO:lda:<1520> log likelihood: -225661\n",
      "INFO:lda:<1530> log likelihood: -225695\n",
      "INFO:lda:<1540> log likelihood: -225670\n",
      "INFO:lda:<1550> log likelihood: -225997\n",
      "INFO:lda:<1560> log likelihood: -225595\n",
      "INFO:lda:<1570> log likelihood: -225726\n",
      "INFO:lda:<1580> log likelihood: -225604\n",
      "INFO:lda:<1590> log likelihood: -225747\n",
      "INFO:lda:<1600> log likelihood: -225597\n",
      "INFO:lda:<1610> log likelihood: -225760\n",
      "INFO:lda:<1620> log likelihood: -225680\n",
      "INFO:lda:<1630> log likelihood: -225688\n",
      "INFO:lda:<1640> log likelihood: -225712\n",
      "INFO:lda:<1650> log likelihood: -225853\n",
      "INFO:lda:<1660> log likelihood: -225680\n",
      "INFO:lda:<1670> log likelihood: -225704\n",
      "INFO:lda:<1680> log likelihood: -225609\n",
      "INFO:lda:<1690> log likelihood: -225800\n",
      "INFO:lda:<1700> log likelihood: -225892\n",
      "INFO:lda:<1710> log likelihood: -225648\n",
      "INFO:lda:<1720> log likelihood: -225497\n",
      "INFO:lda:<1730> log likelihood: -225752\n",
      "INFO:lda:<1740> log likelihood: -225871\n",
      "INFO:lda:<1750> log likelihood: -225740\n",
      "INFO:lda:<1760> log likelihood: -225649\n",
      "INFO:lda:<1770> log likelihood: -225897\n",
      "INFO:lda:<1780> log likelihood: -225576\n",
      "INFO:lda:<1790> log likelihood: -225599\n",
      "INFO:lda:<1800> log likelihood: -225711\n",
      "INFO:lda:<1810> log likelihood: -225684\n",
      "INFO:lda:<1820> log likelihood: -225575\n",
      "INFO:lda:<1830> log likelihood: -225617\n",
      "INFO:lda:<1840> log likelihood: -225547\n",
      "INFO:lda:<1850> log likelihood: -225748\n",
      "INFO:lda:<1860> log likelihood: -225907\n",
      "INFO:lda:<1870> log likelihood: -225449\n",
      "INFO:lda:<1880> log likelihood: -225528\n",
      "INFO:lda:<1890> log likelihood: -225547\n",
      "INFO:lda:<1900> log likelihood: -225564\n",
      "INFO:lda:<1910> log likelihood: -225629\n",
      "INFO:lda:<1920> log likelihood: -225618\n",
      "INFO:lda:<1930> log likelihood: -225429\n",
      "INFO:lda:<1940> log likelihood: -225658\n",
      "INFO:lda:<1950> log likelihood: -225646\n",
      "INFO:lda:<1960> log likelihood: -225729\n",
      "INFO:lda:<1970> log likelihood: -225516\n",
      "INFO:lda:<1980> log likelihood: -225584\n",
      "INFO:lda:<1990> log likelihood: -225653\n",
      "INFO:lda:<1999> log likelihood: -225787\n"
     ]
    }
   ],
   "source": [
    "n_topics = 4\n",
    "n_iter = 2000\n",
    "lda_model = lda.LDA(n_topics=n_topics, n_iter=n_iter)\n",
    "X_topics = lda_model.fit_transform(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02941176,  0.32352941,  0.61764706,  0.02941176],\n",
       "       [ 0.01351351,  0.95945946,  0.01351351,  0.01351351],\n",
       "       [ 0.02272727,  0.47727273,  0.02272727,  0.47727273],\n",
       "       ..., \n",
       "       [ 0.04166667,  0.45833333,  0.04166667,  0.45833333],\n",
       "       [ 0.875     ,  0.04166667,  0.04166667,  0.04166667],\n",
       "       [ 0.02272727,  0.02272727,  0.93181818,  0.02272727]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 8000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 8000\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 0.759967\n",
      "[t-SNE] Error after 300 iterations: 0.759967\n"
     ]
    }
   ],
   "source": [
    "tsne_lda = tsne_model.fit_transform(X_topics)\n",
    "lda_df = pd.DataFrame(tsne_lda, columns=['x','y'])\n",
    "lda_df['len_docs'] = news['tokens'].map(len)\n",
    "def prepareLDAData():\n",
    "    data = {\n",
    "        'vocab': vectorizer.get_feature_names(),\n",
    "        'doc_topic_dists': lda_model.doc_topic_,\n",
    "        'doc_lengths': list(lda_df['len_docs']),\n",
    "        'term_frequency':vectorizer.vocabulary_,\n",
    "        'topic_term_dists': lda_model.components_\n",
    "    } \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldadata=prepareLDAData()\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "prepared_data=pyLDAvis.prepare(**ldadata)\n",
    "pyLDAvis.save_html(prepared_data,'./pyldadavis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
